{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41afe638",
   "metadata": {},
   "source": [
    "# Generate Data Splits for PlantVillage Dataset\n",
    "\n",
    "This notebook converts JPG images from the PlantVillage dataset into TensorFlow tensors and splits them into train/test/validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57864fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print(f\"Keras backend: {keras.backend.backend()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13160b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a4dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bcc9e1a",
   "metadata": {},
   "source": [
    "## 1. Load Metadata and Configure Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d162872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata_path = Path(\"../data/plantvillage_images_metadata.parquet\")\n",
    "df = pd.read_parquet(metadata_path)\n",
    "\n",
    "# Configuration\n",
    "BASE_DATA_PATH = Path(\"../data\")\n",
    "SPLITS_PATH = BASE_DATA_PATH / \"splits\"\n",
    "IMAGE_SIZE = (224, 224)  # Standard size for many pre-trained models\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Use only color images for training (you can change this to 'grayscale' or 'segmented' if needed)\n",
    "IMAGE_TYPE_TO_USE = 'color'\n",
    "\n",
    "print(f\"Total images in metadata: {len(df):,}\")\n",
    "print(f\"Image types available: {df['image_type'].unique()}\")\n",
    "print(f\"\\nUsing image type: {IMAGE_TYPE_TO_USE}\")\n",
    "print(f\"\\nSplit ratios:\")\n",
    "print(f\"  Train: {TRAIN_SPLIT*100}%\")\n",
    "print(f\"  Validation: {VAL_SPLIT*100}%\")\n",
    "print(f\"  Test: {TEST_SPLIT*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eada31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the selected image type\n",
    "df_filtered = df[df['image_type'] == IMAGE_TYPE_TO_USE].copy()\n",
    "\n",
    "# Create a combined label from plant_type and condition\n",
    "df_filtered['label'] = df_filtered['plant_type'] + '___' + df_filtered['condition']\n",
    "\n",
    "# Make paths absolute\n",
    "df_filtered['full_image_path'] = df_filtered['image_path'].apply(\n",
    "    lambda x: BASE_DATA_PATH / x\n",
    ")\n",
    "\n",
    "print(f\"Images after filtering for {IMAGE_TYPE_TO_USE}: {len(df_filtered):,}\")\n",
    "print(f\"\\nNumber of classes: {df_filtered['label'].nunique()}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df_filtered['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2cb27",
   "metadata": {},
   "source": [
    "## 2. Create Stratified Train/Validation/Test Splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split to maintain class distribution\n",
    "# First split: separate train from (val + test)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_filtered,\n",
    "    test_size=(VAL_SPLIT + TEST_SPLIT),\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df_filtered['label']\n",
    ")\n",
    "\n",
    "# Second split: separate val from test\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=TEST_SPLIT / (VAL_SPLIT + TEST_SPLIT),\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=temp_df['label']\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(train_df):,} ({len(train_df)/len(df_filtered)*100:.1f}%)\")\n",
    "print(f\"Validation set size: {len(val_df):,} ({len(val_df)/len(df_filtered)*100:.1f}%)\")\n",
    "print(f\"Test set size: {len(test_df):,} ({len(test_df)/len(df_filtered)*100:.1f}%)\")\n",
    "\n",
    "# Verify class distribution is maintained\n",
    "print(f\"\\nTrain classes: {train_df['label'].nunique()}\")\n",
    "print(f\"Val classes: {val_df['label'].nunique()}\")\n",
    "print(f\"Test classes: {test_df['label'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a848889",
   "metadata": {},
   "source": [
    "## 3. Create Directory Structure and Save Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base splits directory\n",
    "SPLITS_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Create subdirectories for each split\n",
    "for split_name in ['train', 'validation', 'test']:\n",
    "    split_path = SPLITS_PATH / split_name\n",
    "    split_path.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Create class subdirectories\n",
    "    for label in df_filtered['label'].unique():\n",
    "        class_path = split_path / label\n",
    "        class_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"Directory structure created successfully!\")\n",
    "print(f\"\\nBase path: {SPLITS_PATH}\")\n",
    "print(f\"Subdirectories: train, validation, test\")\n",
    "print(f\"Classes per subdirectory: {df_filtered['label'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_split(df, split_name):\n",
    "    \"\"\"Copy images from source to split directory\"\"\"\n",
    "    print(f\"\\nCopying images to {split_name}...\")\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        src_path = row['full_image_path']\n",
    "        label = row['label']\n",
    "        \n",
    "        # Create destination path\n",
    "        dst_path = SPLITS_PATH / split_name / label / src_path.name\n",
    "        \n",
    "        # Copy file if source exists\n",
    "        if src_path.exists():\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "        else:\n",
    "            print(f\"Warning: Source file not found: {src_path}\")\n",
    "    \n",
    "    print(f\"Completed copying {len(df):,} images to {split_name}\")\n",
    "\n",
    "# Copy images to each split\n",
    "copy_images_to_split(train_df, 'train')\n",
    "copy_images_to_split(val_df, 'validation')\n",
    "copy_images_to_split(test_df, 'test')\n",
    "\n",
    "print(\"\\n✓ All images copied successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695391b",
   "metadata": {},
   "source": [
    "## 4. Create Keras Datasets\n",
    "\n",
    "Now we'll create Keras datasets from the organized images. These datasets will:\n",
    "- Load images as tensors\n",
    "- Resize them to a standard size\n",
    "- Normalize pixel values\n",
    "- Apply data augmentation (for training set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for TensorFlow datasets\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Get class names (sorted for consistency)\n",
    "class_names = sorted(df_filtered['label'].unique())\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Image size: {IMAGE_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42266a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets from directories\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    str(SPLITS_PATH / 'train'),\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int',\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_STATE\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    str(SPLITS_PATH / 'validation'),\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    str(SPLITS_PATH / 'test'),\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\n✓ TensorFlow datasets created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56727db",
   "metadata": {},
   "source": [
    "## 5. Normalize and Optimize Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c78647",
   "metadata": {},
   "source": [
    "## 6. Verify Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f0e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset information\n",
    "def get_dataset_info(ds, name):\n",
    "    \"\"\"Get information about a dataset\"\"\"\n",
    "    # Count total batches and samples\n",
    "    num_batches = 0\n",
    "    for _ in ds:\n",
    "        num_batches += 1\n",
    "    \n",
    "    print(f\"\\n{name} Dataset:\")\n",
    "    print(f\"  Number of batches: {num_batches}\")\n",
    "    print(f\"  Approximate number of samples: {num_batches * BATCH_SIZE}\")\n",
    "    \n",
    "    # Get a sample batch\n",
    "    for images, labels in ds.take(1):\n",
    "        print(f\"  Batch shape: {images.shape}\")\n",
    "        print(f\"  Label shape: {labels.shape}\")\n",
    "        print(f\"  Image dtype: {images.dtype}\")\n",
    "        print(f\"  Pixel value range: [{tf.reduce_min(images).numpy():.3f}, {tf.reduce_max(images).numpy():.3f}]\")\n",
    "\n",
    "get_dataset_info(train_ds, \"Training\")\n",
    "get_dataset_info(val_ds, \"Validation\")\n",
    "get_dataset_info(test_ds, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize a batch of images from the training set\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(min(9, len(images))):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy())\n",
    "        plt.title(f\"Class: {train_ds.class_names[labels[i]]}\", fontsize=8)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Sample Images from Training Set (with augmentation)\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c042c977",
   "metadata": {},
   "source": [
    "## 7. Save Dataset Configuration and Metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the split information for reproducibility\n",
    "train_df.to_csv(SPLITS_PATH / 'train_metadata.csv', index=False)\n",
    "val_df.to_csv(SPLITS_PATH / 'validation_metadata.csv', index=False)\n",
    "test_df.to_csv(SPLITS_PATH / 'test_metadata.csv', index=False)\n",
    "\n",
    "# Save class names\n",
    "with open(SPLITS_PATH / 'class_names.txt', 'w') as f:\n",
    "    for class_name in train_ds.class_names:\n",
    "        f.write(f\"{class_name}\\n\")\n",
    "\n",
    "# Save configuration\n",
    "import json\n",
    "\n",
    "config = {\n",
    "    'image_size': IMAGE_SIZE,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'train_split': TRAIN_SPLIT,\n",
    "    'val_split': VAL_SPLIT,\n",
    "    'test_split': TEST_SPLIT,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'image_type': IMAGE_TYPE_TO_USE,\n",
    "    'num_classes': num_classes,\n",
    "    'train_samples': len(train_df),\n",
    "    'val_samples': len(val_df),\n",
    "    'test_samples': len(test_df),\n",
    "    'total_samples': len(df_filtered)\n",
    "}\n",
    "\n",
    "with open(SPLITS_PATH / 'dataset_config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(\"✓ Metadata and configuration saved!\")\n",
    "print(f\"\\nSaved files in {SPLITS_PATH}:\")\n",
    "print(\"  - train_metadata.csv\")\n",
    "print(\"  - validation_metadata.csv\")\n",
    "print(\"  - test_metadata.csv\")\n",
    "print(\"  - class_names.txt\")\n",
    "print(\"  - dataset_config.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d83e2",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### What we've accomplished:\n",
    "\n",
    "1. **Loaded and filtered the PlantVillage metadata** - Selected color images for training\n",
    "2. **Created stratified splits** - Maintained class distribution across train/validation/test sets\n",
    "3. **Organized images** - Copied images to `data/splits/` with proper directory structure\n",
    "4. **Created TensorFlow datasets** - Images are now loaded as tensors ready for training\n",
    "5. **Applied preprocessing** - Normalized pixel values and added data augmentation for training\n",
    "6. **Saved metadata** - Stored configuration and split information for reproducibility\n",
    "\n",
    "### Next steps for model training:\n",
    "\n",
    "```python\n",
    "# To use these datasets in your training script:\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'data/splits/train',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'data/splits/validation',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'data/splits/test',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Apply normalization and train your model\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d5100",
   "metadata": {},
   "source": [
    "## 9. (Optional) Save TensorFlow Datasets to Disk\n",
    "\n",
    "You can optionally save the preprocessed TensorFlow datasets to disk for faster loading in the future. This is useful when you have expensive preprocessing steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines to save the datasets to disk\n",
    "# This will save the preprocessed datasets in TensorFlow format\n",
    "\n",
    "# # Save datasets\n",
    "# train_ds.save(str(SPLITS_PATH / 'train_dataset'))\n",
    "# val_ds.save(str(SPLITS_PATH / 'validation_dataset'))\n",
    "# test_ds.save(str(SPLITS_PATH / 'test_dataset'))\n",
    "# \n",
    "# print(\"✓ TensorFlow datasets saved to disk!\")\n",
    "# print(f\"\\nTo load them later:\")\n",
    "# print(\"train_ds = tf.data.Dataset.load(str(SPLITS_PATH / 'train_dataset'))\")\n",
    "# print(\"val_ds = tf.data.Dataset.load(str(SPLITS_PATH / 'validation_dataset'))\")\n",
    "# print(\"test_ds = tf.data.Dataset.load(str(SPLITS_PATH / 'test_dataset'))\")\n",
    "\n",
    "print(\"\\nNote: Saving TensorFlow datasets to disk is commented out by default.\")\n",
    "print(\"The current approach (organizing images in folders) is more flexible and recommended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization layer (scales pixel values from [0, 255] to [0, 1])\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "# Data augmentation for training set\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "def prepare_dataset(ds, augment=False):\n",
    "    \"\"\"Prepare dataset with normalization and optional augmentation\"\"\"\n",
    "    # Normalize\n",
    "    ds = ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # Apply augmentation if requested\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                    num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # Prefetch for performance\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# Prepare datasets\n",
    "train_ds = prepare_dataset(train_ds, augment=True)\n",
    "val_ds = prepare_dataset(val_ds, augment=False)\n",
    "test_ds = prepare_dataset(test_ds, augment=False)\n",
    "\n",
    "print(\"✓ Datasets normalized and optimized!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec2d53",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
